{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment\n",
    "# This cell only needed the first time you use this notebook on a system\n",
    "import sys,os,os.path\n",
    "os.environ['IBM_DB_HOME']='C:\\Program Files\\IBM\\SQLLIB'\n",
    "# Check to see if the libraries already have been installed\n",
    "import importlib\n",
    "# Check for ibm_db_sa.  If it exists, it's safe to assume that the other requirements\n",
    "# are already installed.\n",
    "spec = importlib.util.find_spec(\"ibm_db_sa\")\n",
    "if spec is None:\n",
    "    print(\"Installing prerequisites.\")\n",
    "    !pip install ipython-sql\n",
    "    !pip install \"ibm-db==2.0.8a\"\n",
    "    !pip install ibm_db_sa\n",
    "else:\n",
    "    print(\"sql magic, ibm_db and ibm_db_sa already installed.\")\n",
    "spec = importlib.util.find_spec(\"sqlparse\")\n",
    "if spec is None:\n",
    "    print(\"Installing prerequisites.\")\n",
    "    !pip install sqlparse\n",
    "else:\n",
    "    print(\"sqlparse already installed.\")\n",
    "# Restart the Kernel if this is your first time installing the above. The next steps will fail unless you do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules and load the SQL magic\n",
    "import ibm_db\n",
    "import ibm_db_sa\n",
    "import sqlalchemy\n",
    "%load_ext sql\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import datetime\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import sqlparse\n",
    "from urllib.parse import unquote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filename for passwords\n",
    "filename = 'ember_variables.py'\n",
    "# source the file\n",
    "%run $filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the database. Change the values of user, host, and password to match your environment. \n",
    "#For connection to a local host, use 'localhost' for the host name. \n",
    "#Also change the port number and database name.\n",
    "user=User\n",
    "host=Host\n",
    "inst=insts[0]\n",
    "\n",
    "password=PW\n",
    "db=dbs['SAMPLE'][0]\n",
    "port=ports['SAMPLE']\n",
    "\n",
    "schema='DB2INST1'\n",
    "\n",
    "%sql db2+ibm_db://$user:$password@$host:$port/$db\n",
    "#%sql db2+ibm_db://$user:$pw_parse@$host:$port/$db\n",
    "\n",
    "print(\"Database: \"+db)\n",
    "print(\"Host: \"+host)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hide code cells\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, run query to identify top problem queries and gather metrics about those SQL statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql prob_sql << WITH SUM_TAB (SUM_RR, SUM_CPU, SUM_EXEC, SUM_SORT, SUM_NUM_EXEC) AS ( \n",
    "        SELECT  nullif(FLOAT(SUM(ROWS_READ)),0), \n",
    "                nullif(FLOAT(SUM(TOTAL_CPU_TIME)),0), \n",
    "                nullif(FLOAT(SUM(STMT_EXEC_TIME)),0), \n",
    "                nullif(FLOAT(SUM(TOTAL_SECTION_SORT_TIME)),0), \n",
    "                nullif(FLOAT(SUM(NUM_EXECUTIONS)),0) \n",
    "            FROM TABLE(MON_GET_PKG_CACHE_STMT ( 'D', NULL, NULL, -2)) AS T \n",
    "            WHERE stmt_text not like '%monreport.dbsummary%'\n",
    "        ) \n",
    "SELECT substr(stmt_text,1,25) as STATEMENT, \n",
    "        ROWS_READ, \n",
    "        coalesce(DECIMAL(100*(FLOAT(ROWS_READ)/SUM_TAB.SUM_RR),5,2),0) AS PCT_TOT_RR, \n",
    "        TOTAL_CPU_TIME, \n",
    "        coalesce(DECIMAL(100*(FLOAT(TOTAL_CPU_TIME)/SUM_TAB.SUM_CPU),5,2),0) AS PCT_TOT_CPU, \n",
    "        STMT_EXEC_TIME, \n",
    "        coalesce(DECIMAL(100*(FLOAT(STMT_EXEC_TIME)/SUM_TAB.SUM_EXEC),5,2),0) AS PCT_TOT_EXEC_TIME, \n",
    "        TOTAL_SECTION_SORT_TIME, \n",
    "        coalesce(DECIMAL(100*(FLOAT(TOTAL_SECTION_SORT_TIME)/SUM_TAB.SUM_SORT),5,2),0) AS PCT_TOT_SRT, \n",
    "        NUM_EXECUTIONS, \n",
    "        coalesce(DECIMAL(100*(FLOAT(NUM_EXECUTIONS)/SUM_TAB.SUM_NUM_EXEC),5,2),0) AS PCT_TOT_EXECS, \n",
    "        DECIMAL(FLOAT(STMT_EXEC_TIME)/FLOAT(NUM_EXECUTIONS),10,2) AS AVG_EXEC_TIME, \n",
    "        INSERT_TIMESTAMP,\n",
    "        hex(EXECUTABLE_ID) as EXECUTABLE_ID,\n",
    "        RTRIM(STMT_TEXT) as FULL_STATEMENT \n",
    "    FROM TABLE(MON_GET_PKG_CACHE_STMT ( 'D', NULL, NULL, -2)) AS T, SUM_TAB \n",
    "    WHERE (DECIMAL(100*(FLOAT(ROWS_READ)/SUM_TAB.SUM_RR),5,2) > 10 \n",
    "            OR DECIMAL(100*(FLOAT(TOTAL_CPU_TIME)/SUM_TAB.SUM_CPU),5,2) >10 \n",
    "            OR DECIMAL(100*(FLOAT(STMT_EXEC_TIME)/SUM_TAB.SUM_EXEC),5,2) >10 \n",
    "            OR DECIMAL(100*(FLOAT(TOTAL_SECTION_SORT_TIME)/SUM_TAB.SUM_SORT),5,2) >10 \n",
    "            OR DECIMAL(100*(FLOAT(NUM_EXECUTIONS)/SUM_TAB.SUM_NUM_EXEC),5,2) >10 )\n",
    "        AND stmt_text not like '%monreport.dbsummary%'\n",
    "    ORDER BY ROWS_READ DESC \n",
    "    FETCH FIRST 20 ROWS ONLY \n",
    "    WITH UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=prob_sql.DataFrame()\n",
    "#df = pd.read_csv(r\"C:\\Users\\ecrooks\\Documents\\GitHub\\private_jupyter_notebooks\\problem_sql.csv\")\n",
    "\n",
    "#display(df.columns)\n",
    "df[['pct_tot_rr']]=df[['pct_tot_rr']].astype(float)\n",
    "df[['pct_tot_cpu']]=df[['pct_tot_cpu']].astype(float)\n",
    "df[['pct_tot_exec_time']]=df[['pct_tot_exec_time']].astype(float)\n",
    "df[['pct_tot_srt']]=df[['pct_tot_srt']].astype(float)\n",
    "df[['pct_tot_execs']]=df[['pct_tot_execs']].astype(float)\n",
    "df[['avg_exec_time']]=df[['avg_exec_time']].astype(float)\n",
    "\n",
    "df['rows_read'] = df['rows_read'].map(lambda x: '{:,}'.format(x))\n",
    "df['total_cpu_time'] = df['total_cpu_time'].map(lambda x: '{:,}'.format(x))\n",
    "df['stmt_exec_time'] = df['stmt_exec_time'].map(lambda x: '{:,}'.format(x))\n",
    "df['total_section_sort_time'] = df['total_section_sort_time'].map(lambda x: '{:,}'.format(x))\n",
    "df['num_executions'] = df['num_executions'].map(lambda x: '{:,}'.format(x))\n",
    "\n",
    "#pd.options.display.float_format = '{:,.2f}'.format\n",
    "display(df[['STATEMENT','rows_read','pct_tot_rr','total_cpu_time','pct_tot_cpu','stmt_exec_time','pct_tot_exec_time','total_section_sort_time','pct_tot_srt','num_executions','pct_tot_execs','avg_exec_time']])\n",
    "#df.plot(x='STATEMENT', y=['pct_tot_rr','pct_tot_cpu','pct_tot_exec_time','pct_tot_srt'], kind='barh')\n",
    "#plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=len(df)\n",
    "df_add=df\n",
    "df_add.loc[pos] = pd.Series('OTHER', index = ['STATEMENT'])\n",
    "df_add.at[pos, 'pct_tot_rr'] = 100 - df['pct_tot_rr'].sum()\n",
    "df_add.at[pos, 'pct_tot_cpu'] = 100 - df['pct_tot_cpu'].sum()\n",
    "df_add.at[pos, 'pct_tot_exec_time'] = 100 - df['pct_tot_exec_time'].sum()\n",
    "df_add.at[pos, 'pct_tot_srt'] = 100 - df['pct_tot_srt'].sum()\n",
    "df_add.at[pos, 'pct_tot_execs'] = 100 - df['pct_tot_execs'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add['query_num'] = df_add.index\n",
    "df_add['query_num']=df_add['query_num'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "df_add[['query_num']]= 'query' + df[['query_num']]\n",
    "df_add.at[pos, 'query_num'] = 'other'\n",
    "\n",
    "#display(df_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add2=df_add.drop(['rows_read', 'total_cpu_time', 'stmt_exec_time', 'total_section_sort_time', 'num_executions', 'avg_exec_time', 'insert_timestamp', 'executable_id', 'STATEMENT', 'full_statement'], axis=1)\n",
    "#display(df_add2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add3=df_add2.set_index('query_num').T\n",
    "\n",
    "df_add3.rename(index={'pct_tot_rr':'Rows Read'},inplace=True)\n",
    "df_add3.rename(index={'pct_tot_cpu':'CPU Time'},inplace=True)\n",
    "df_add3.rename(index={'pct_tot_exec_time':'Execution Time'},inplace=True)\n",
    "df_add3.rename(index={'pct_tot_srt':'Sort Time'},inplace=True)\n",
    "df_add3.rename(index={'pct_tot_execs':'Number of Executions'},inplace=True)\n",
    "#display(df_add3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Utilization by Problem Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_add3.plot(kind='barh', title =\"Percent of Resource Consumption by Top Problem Queries\",figsize=(15,10),legend=True, stacked=True, fontsize=12, colormap='Paired')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Query Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn=%sql\n",
    "#display(conn)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "for index, row in df.iterrows():\n",
    "    # skip the \"other\" row added to balance out numbers for the metrics\n",
    "    if row['query_num'] == 'other': \n",
    "        continue\n",
    "    # Display basic information about the query\n",
    "    display(Markdown(\"## Query \"+str(index)))\n",
    "    display(Markdown(\"### Query Characteristics\"))\n",
    "    display(Markdown(\"Executed \"+str(row['num_executions'])+\" times since last placed in the package cache at \"+str(row['insert_timestamp'])))\n",
    "    display(Markdown(\"Consumed \"+str(row['pct_tot_rr'])+\" percent of all rows read by all queries in the package cache.\"))\n",
    "    display(Markdown(\"Consumed \"+str(row['pct_tot_cpu'])+\" percent of all cpu time used by all queries in the package cache.\"))\n",
    "    display(Markdown(\"Consumed \"+str(row['pct_tot_exec_time'])+\" percent of all execution time used by all queries in the package cache.\"))\n",
    "    display(Markdown(\"Consumed \"+str(row['pct_tot_srt'])+\" percent of all sort time used by all queries in the package cache.\"))\n",
    "    display(Markdown(\"### Query Text\"))\n",
    "    formatted_sql=sqlparse.format(df['full_statement'][index], reindent=True)\n",
    "    print(formatted_sql.replace(\"\\\\n\",\"<br>\"))\n",
    "    # If a database connection is available, gather additional information about this query\n",
    "    ## Note: explain may fail if the interval between runing the query to find problem sql and this section was too long, and the section has been cleared from the package cache\n",
    "    if conn:\n",
    "        #When db connection is available\n",
    "        display(Markdown(\"### Query Explain Plan\"))\n",
    "        display(row.dtypes)\n",
    "        exe_id=row['executable_id']\n",
    "        ex_schema='SYSTOOLS'\n",
    "        ex_requester=''\n",
    "        ex_time=''\n",
    "        src_name=''\n",
    "        src_schema=schema\n",
    "        src_version=''\n",
    "        %sql call explain_from_section(x'{exe_id}', 'M', NULL, 0, :ex_schema, :ex_requester, :ex_time, :src_name, :src_schema, :src_version)\n",
    "        expln_plan=%sql select * from vdba.last_explained\n",
    "        print(expln_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
