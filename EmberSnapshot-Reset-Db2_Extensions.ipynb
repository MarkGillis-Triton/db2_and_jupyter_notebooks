{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Notes\n",
    "This notebook should be launched from a session of jupyter notebook that was launched from a DB2 command window\n",
    "To do this, run an administrator DB2 command window as an administrator and type 'jupyter notebook'\n",
    "\n",
    "If you don't know what to do right now, try:\n",
    "1. Update the database connectivity file with your database connectivity information\n",
    "1. Click on each code sell in the \"Environment set up\" section and select \"Run Cells\" from the Cell menu on the toolbar immediately below the name of this notebook.\n",
    "1.  On the Kernel menu, select \"Restart & Run All\"\n",
    "\n",
    "If you have set up your enviornment before or used this Notebook before, then select \"Cell\" on the toolbar just under the name of this notebook, and select \"run all\". If database credentials are properly defined, this will generate the snapshot data using values since the last database start.\n",
    "\n",
    "To emulate monitor reset, click the link that says \"Collect baselines (reset monitor switches all)\" below\n",
    "\n",
    "To generate values based on the reset values, click on the text that says \"Generate snapshot based on reset values\", and then select \"Run all Below\" on the Cell menu to generate snapshot data based on a previously collected baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set up:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Db2 Extensions from  https://github.com/DB2-Samples/db2jupyter and place db2.ipyndb in the same folder as this jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "os.environ['IBM_DB_HOME']='C:\\Program Files\\IBM\\SQLLIB'\n",
    "!pip install ipython-sql\n",
    "!pip install ibm_db \n",
    "!pip install ibm_db_sa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the Kernel if this is your first time installing the above. The next steps will fail unless you do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the modules and load the SQL magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This cell must be executed any time the Kernel is started or restarted\n",
    "%run db2.ipynb\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Hide code cells\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database. Change the values of user, host, and password to match your environment. For connection to a local host, use 'localhost' for the host name. Also change the port number and database name in the connection string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baselines=0\n",
    "user='db2admin'\n",
    "host='localhost'\n",
    "# Define filename for passwords\n",
    "filename = 'ember_variables.py'\n",
    "# source the file\n",
    "%run $filename\n",
    "password = LocalDB2password\n",
    "port=50000\n",
    "db='SAMPLE'\n",
    "%sql CONNECT TO $db USER $user USING ? HOST $host PORT 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Collect Baselines\n",
    "HTML('''<script>\n",
    "collect_baseline=false; \n",
    "function collect_baselines() {\n",
    " var kernel = IPython.notebook.kernel;\n",
    " collect_baseline=true;\n",
    " if (collect_baseline){\n",
    " kernel.execute('baseline_ts = %sql select current timestamp from sysibm.sysdummy1');\n",
    " kernel.execute('mgd_baseline = %sql select * from table(mon_get_database(-2)) as mgd');\n",
    " kernel.execute('mgtl_baseline = %sql select * from table(mon_get_transaction_log(-2)) as mgtl');\n",
    " kernel.execute('mgbp_baseline = %sql select * from table(mon_get_bufferpool(NULL,-2)) mgbp');\n",
    " kernel.execute('baselines=1');\n",
    " window.alert('Baselines Collected')\n",
    " }\n",
    "} \n",
    "\n",
    "</script>\n",
    "The baselines are not collected by default.\n",
    "<a href=\"javascript:collect_baselines()\">Collect baselines (reset monitor switches all)</a>.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate snapshot based on reset values: Click on this text and then select \"Run all Below\" on the Cell menu to generate snapshot data based on a previously collected baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## To reset the monitor values, run this cell\n",
    "## Baseline\n",
    "#baseline_ts = %sql select current timestamp from sysibm.sysdummy1\n",
    "#mgd_baseline = %sql select * from table(mon_get_database(-2)) as mgd\n",
    "#mgtl_baseline = %sql select * from table(mon_get_transaction_log(-2)) as mgtl\n",
    "#mgbp_baseline = %sql select * from table(mon_get_bufferpool(NULL,-2)) mgbp\n",
    "#baselines=1\n",
    "\n",
    "try:\n",
    "    baseline_ts\n",
    "except NameError:\n",
    "    print(\"No baseline values defined. Data is since last database activation\")\n",
    "else:\n",
    "    print(baseline_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Db2 Snapshot\n",
    "Ember's snapshot for Db2 (LUW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Uptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!db2pd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database active since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_conn_time=%sql select db_conn_time from table(mon_get_database(-2)) as mgd\n",
    "db_conn_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five most recent activation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Not working, come back to it\n",
    "%sql select * \\\n",
    "from table(pd_get_log_msgs(current timestamp - 7 days, -2))\\\n",
    "where DBNAME= '{db}' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Last Succesful Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql with ts as (select EID from sysibmadm.db_history where start_time = (select max(timestamp(start_time)) as ts  \\\n",
    "\t\tfrom sysibmadm.db_history \\\n",
    "\t\twhere operation='B' and SQLCODE is NULL)\\\n",
    "\t) \\\n",
    "select case \\\n",
    "\t\twhen operationtype = 'D' then 'DELTA_OFFLINE'\\\n",
    "\t\twhen operationtype = 'E' then 'DELTA_ONLINE' \\\n",
    "\t\twhen operationtype = 'F' then 'OFFLINE' \\\n",
    "\t\twhen operationtype = 'I' then 'INCR_OFFLINE' \\\n",
    "\t\twhen operationtype = 'N' then 'ONLINE' \\\n",
    "\t\twhen operationtype = 'O' then 'INCR_ONLINE' \\\n",
    "\t\telse operationtype \\\n",
    "\tend as type \\\n",
    "        , to_char(timestamp(start_time), 'YYYY-MM-DD HH24:MI:SS')  as backup_time \\\n",
    "FROM sysibmadm.db_history dh \\\n",
    "\tjoin ts on dh.eid = ts.eid \\\n",
    "ORDER BY start_time desc \\\n",
    "fetch first 1 row only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HADR details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#untested - test on HADR database\n",
    "%sql select hadr_role \\\n",
    "    , hadr_state \\\n",
    "    , hadr_connect_status \\\n",
    "    , hadr_log_gap \\\n",
    "FROM table(mon_get_hadr(-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select count(*) as NUM_TBSPS_NOT_AUTORESIZE \\\n",
    "FROM table(mon_get_tablespace(NULL,-2)) \\\n",
    "WHERE TBSP_AUTO_RESIZE_ENABLED=0 \\\n",
    "    AND TBSP_TYPE='DMS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select tbsp_name \\\n",
    "    , decimal(float(tbsp_used_pages)/float(tbsp_usable_pages),5,2) as pct_full \\\n",
    "FROM table(mon_get_tablespace(NULL,-2)) \\\n",
    "WHERE TBSP_TYPE='DMS' \\\n",
    "    AND (TBSP_AUTO_RESIZE_ENABLED=0 OR TBSP_LAST_RESIZE_FAILED=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Read Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if baselines == 1:\n",
    "    read_eff=%sql select decimal((float(rows_read)-{mgd_baseline.loc[0,\"ROWS_READ\"]})/(float(rows_returned)-{mgd_baseline.loc[0,\"ROWS_READ\"]}),16,2) read_eff \\\n",
    "    from table(mon_get_database(-2)) as mgd \n",
    "else:\n",
    "    read_eff=%sql select decimal(float(rows_read)/float(rows_returned),16,2) read_eff \\\n",
    "    from table(mon_get_database(-2)) as mgd\n",
    "read_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%sql select rows_modified \\\n",
    "#from table(mon_get_database(-2)) as mgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%sql select rows_modified - {mgd_baseline[0].rows_modified} \\\n",
    "#from table(mon_get_database(-2)) as mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer Pool Hit Ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if baselines == 1:\n",
    "    bp_details = %sql select \\\n",
    "        (pool_data_l_reads-{mgd_baseline.loc[0,\"POOL_DATA_L_READS\"]} + pool_xda_l_reads-{mgd_baseline.loc[0,\"POOL_XDA_L_READS\"]} + pool_index_l_reads-{mgd_baseline.loc[0,\"POOL_INDEX_L_READS\"]}) as total_l_reads \\\n",
    "        , case when pool_data_l_reads-{mgd_baseline.loc[0,\"POOL_DATA_L_READS\"]} > 0 or pool_temp_data_l_reads-{mgd_baseline.loc[0,\"POOL_TEMP_DATA_L_READS\"]} > 0 \\\n",
    "            then decimal(((float(pool_data_lbp_pages_found-{mgd_baseline.loc[0,\"POOL_DATA_LBP_PAGES_FOUND\"]}) - float(pool_async_data_lbp_pages_found-{mgd_baseline.loc[0,\"POOL_ASYNC_DATA_LBP_PAGES_FOUND\"]})) / (float(pool_data_l_reads-{mgd_baseline.loc[0,\"POOL_DATA_L_READS\"]}) + float(pool_temp_data_l_reads-{mgd_baseline.loc[0,\"POOL_TEMP_DATA_L_READS\"]}))) * 100,5,2) \\\n",
    "            else -1 end as data_hit_ratio_percent \\\n",
    "        , case when pool_index_l_reads-{mgd_baseline.loc[0,\"POOL_INDEX_L_READS\"]} > 0 or pool_temp_index_l_reads-{mgd_baseline.loc[0,\"POOL_TEMP_INDEX_L_READS\"]} > 0 \\\n",
    "            then decimal(((float(pool_index_lbp_pages_found-{mgd_baseline.loc[0,\"POOL_INDEX_LBP_PAGES_FOUND\"]}) - float(pool_async_index_lbp_pages_found-{mgd_baseline.loc[0,\"POOL_ASYNC_INDEX_LBP_PAGES_FOUND\"]})) / (float(pool_index_l_reads-{mgd_baseline.loc[0,\"POOL_INDEX_L_READS\"]}) + float(pool_temp_index_l_reads-{mgd_baseline.loc[0,\"POOL_TEMP_INDEX_L_READS\"]}))) * 100,5,2) \\\n",
    "            else -1 end as index_hit_ratio_percent \\\n",
    "        , case when pool_xda_l_reads-{mgd_baseline.loc[0,\"POOL_XDA_L_READS\"]} > 0 or pool_temp_xda_l_reads-{mgd_baseline.loc[0,\"POOL_TEMP_XDA_L_READS\"]} > 0 \\\n",
    "             then decimal(((float(pool_xda_lbp_pages_found-{mgd_baseline.loc[0,\"POOL_XDA_LBP_PAGES_FOUND\"]}) - float(pool_async_xda_lbp_pages_found-{mgd_baseline.loc[0,\"POOL_ASYNC_XDA_LBP_PAGES_FOUND\"]})) / (float(pool_xda_l_reads-{mgd_baseline.loc[0,\"POOL_XDA_L_READS\"]}) + float(pool_temp_xda_l_reads-{mgd_baseline.loc[0,\"POOL_TEMP_XDA_L_READS\"]}))) * 100,5,2) \\\n",
    "             else -1 end as xda_hit_ratio_percent \\\n",
    "        , case when pool_col_l_reads-{mgd_baseline.loc[0,\"POOL_COL_L_READS\"]} > 0 or pool_temp_col_l_reads-{mgd_baseline.loc[0,\"POOL_TEMP_COL_L_READS\"]} > 0 \\\n",
    "             then decimal(((float(pool_col_lbp_pages_found-{mgd_baseline.loc[0,\"POOL_COL_LBP_PAGES_FOUND\"]}) - float(pool_async_col_lbp_pages_found-{mgd_baseline.loc[0,\"POOL_ASYNC_COL_LBP_PAGES_FOUND\"]})) / (float(pool_col_l_reads-{mgd_baseline.loc[0,\"POOL_COL_L_READS\"]}) + float(pool_temp_col_l_reads-{mgd_baseline.loc[0,\"POOL_TEMP_COL_L_READS\"]}))) * 100,5,2) \\\n",
    "             else -1 end as col_hit_ratio_percent \\\n",
    "    from table(mon_get_database(-2)) mgd \n",
    "    \n",
    "else:\n",
    "    bp_details = %sql select \\\n",
    "        (pool_data_l_reads + pool_xda_l_reads + pool_index_l_reads) as total_l_reads \\\n",
    "        , case when pool_data_l_reads > 0 or pool_temp_data_l_reads > 0 \\\n",
    "            then decimal(((float(pool_data_lbp_pages_found) - float(pool_async_data_lbp_pages_found)) / (float(pool_data_l_reads) + float(pool_temp_data_l_reads))) * 100,5,2) \\\n",
    "            else -1 end as data_hit_ratio_percent \\\n",
    "        , case when pool_index_l_reads > 0 or pool_temp_index_l_reads > 0 \\\n",
    "            then decimal(((float(pool_index_lbp_pages_found) - float(pool_async_index_lbp_pages_found)) / (float(pool_index_l_reads) + float(pool_temp_index_l_reads))) * 100,5,2) \\\n",
    "            else -1 end as index_hit_ratio_percent \\\n",
    "        , case when pool_xda_l_reads > 0 or pool_temp_xda_l_reads > 0 \\\n",
    "             then decimal(((float(pool_xda_lbp_pages_found) - float(pool_async_xda_lbp_pages_found)) / (float(pool_xda_l_reads) + float(pool_temp_xda_l_reads))) * 100,5,2) \\\n",
    "             else -1 end as xda_hit_ratio_percent \\\n",
    "        , case when pool_col_l_reads > 0 or pool_temp_col_l_reads > 0 \\\n",
    "             then decimal(((float(pool_col_lbp_pages_found) - float(pool_async_col_lbp_pages_found)) / (float(pool_col_l_reads) + float(pool_temp_col_l_reads))) * 100,5,2) \\\n",
    "             else -1 end as col_hit_ratio_percent \\\n",
    "    from table(mon_get_database(-2)) mgd\n",
    "bp_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Bufferpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=None\n",
    "df = pandas.DataFrame()\n",
    "if baselines == 1:\n",
    "    for ind, row in mgbp_baseline.iterrows():\n",
    "        this_bp=row['BP_NAME']\n",
    "        if this_bp.startswith(\"IBMSYS\"):\n",
    "            #skip this bp, as it is one of the small default ones\n",
    "            meh=1\n",
    "        else:\n",
    "            df = %sql select bp_name \\\n",
    "                , (pool_data_l_reads-{row['POOL_DATA_L_READS']} + pool_xda_l_reads-{row['POOL_XDA_L_READS']} + pool_index_l_reads-{row['POOL_INDEX_L_READS']}) as total_l_reads \\\n",
    "                , case when pool_data_l_reads-{row['POOL_DATA_L_READS']} > 0 or pool_temp_data_l_reads-{row['POOL_TEMP_DATA_L_READS']} > 0 \\\n",
    "                    then decimal(((float(pool_data_lbp_pages_found-{row['POOL_DATA_LBP_PAGES_FOUND']}) - float(pool_async_data_lbp_pages_found-{row['POOL_ASYNC_DATA_LBP_PAGES_FOUND']})) / (float(pool_data_l_reads-{row['POOL_DATA_L_READS']}) + float(pool_temp_data_l_reads-{row['POOL_TEMP_DATA_L_READS']}))) * 100,5,2) \\\n",
    "                    else -1 end as data_hit_ratio_percent \\\n",
    "                , case when pool_index_l_reads-{row['POOL_INDEX_L_READS']} > 0 or pool_temp_index_l_reads-{row['POOL_TEMP_INDEX_L_READS']} > 0 \\\n",
    "                    then decimal(((float(pool_index_lbp_pages_found-{row['POOL_INDEX_LBP_PAGES_FOUND']}) - float(pool_async_index_lbp_pages_found-{row['POOL_ASYNC_INDEX_LBP_PAGES_FOUND']})) / (float(pool_index_l_reads-{row['POOL_INDEX_L_READS']}) + float(pool_temp_index_l_reads-{row['POOL_TEMP_INDEX_L_READS']}))) * 100,5,2) \\\n",
    "                    else -1 end as index_hit_ratio_percent \\\n",
    "                , case when pool_xda_l_reads-{row['POOL_XDA_L_READS']} > 0 or pool_temp_xda_l_reads-{row['POOL_TEMP_XDA_L_READS']} > 0 \\\n",
    "                     then decimal(((float(pool_xda_lbp_pages_found-{row['POOL_XDA_LBP_PAGES_FOUND']}) - float(pool_async_xda_lbp_pages_found-{row['POOL_ASYNC_XDA_LBP_PAGES_FOUND']})) / (float(pool_xda_l_reads-{row['POOL_XDA_L_READS']}) + float(pool_temp_xda_l_reads-{row['POOL_TEMP_XDA_L_READS']}))) * 100,5,2) \\\n",
    "                     else -1 end as xda_hit_ratio_percent \\\n",
    "                , case when pool_col_l_reads-{row['POOL_COL_L_READS']} > 0 or pool_temp_col_l_reads-{row['POOL_TEMP_COL_L_READS']} > 0 \\\n",
    "                     then decimal(((float(pool_col_lbp_pages_found-{row['POOL_COL_LBP_PAGES_FOUND']}) - float(pool_async_col_lbp_pages_found-{row['POOL_ASYNC_COL_LBP_PAGES_FOUND']})) / (float(pool_col_l_reads-{row['POOL_COL_L_READS']}) + float(pool_temp_col_l_reads-{row['POOL_TEMP_COL_L_READS']}))) * 100,5,2) \\\n",
    "                     else -1 end as col_hit_ratio_percent \\\n",
    "            from table(mon_get_bufferpool(NULL,-2)) mgbp \\\n",
    "            WHERE mgbp.bp_name not like 'IBMSYS%' \\\n",
    "                and mgbp.bp_name='{this_bp}'\n",
    "        df = df.append(bp_details)\n",
    "        bp_details=None\n",
    "else:\n",
    "    df = %sql select mgbp.bp_name \\\n",
    "        , (pool_data_l_reads + pool_xda_l_reads + pool_index_l_reads) as total_l_reads \\\n",
    "        , case when pool_data_l_reads > 0 or pool_temp_data_l_reads > 0 \\\n",
    "            then decimal(((float(pool_data_lbp_pages_found) - float(pool_async_data_lbp_pages_found)) / (float(pool_data_l_reads) + float(pool_temp_data_l_reads))) * 100,5,2) \\\n",
    "            else -1 end as data_hit_ratio_percent \\\n",
    "        , case when pool_index_l_reads > 0 or pool_temp_index_l_reads > 0 \\\n",
    "            then decimal(((float(pool_index_lbp_pages_found) - float(pool_async_index_lbp_pages_found)) / (float(pool_index_l_reads) + float(pool_temp_index_l_reads))) * 100,5,2) \\\n",
    "            else -1 end as index_hit_ratio_percent \\\n",
    "        , case when pool_xda_l_reads > 0 or pool_temp_xda_l_reads > 0 \\\n",
    "             then decimal(((float(pool_xda_lbp_pages_found) - float(pool_async_xda_lbp_pages_found)) / (float(pool_xda_l_reads) + float(pool_temp_xda_l_reads))) * 100,5,2) \\\n",
    "             else -1 end as xda_hit_ratio_percent \\\n",
    "        , case when pool_col_l_reads > 0 or pool_temp_col_l_reads > 0 \\\n",
    "             then decimal(((float(pool_col_lbp_pages_found) - float(pool_async_col_lbp_pages_found)) / (float(pool_col_l_reads) + float(pool_temp_col_l_reads))) * 100,5,2) \\\n",
    "             else -1 end as col_hit_ratio_percent \\\n",
    "    from table(mon_get_bufferpool(NULL,-2)) mgbp \\\n",
    "    WHERE mgbp.bp_name not like 'IBMSYS%'\n",
    "    #return(bp_details)\n",
    "    df = df.append(bp_details)\n",
    "    bp_details=None\n",
    "#bp_details\n",
    "df.columns = ['BP Name', 'Logical Reads', 'Data Hit Ratio', 'Index Hit Ratio', 'XML Hit Ratio', 'Column Hit Ratio']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if baselines == 1:\n",
    "    pkg_cache=%sql select \\\n",
    "        case when pkg_cache_lookups-{mgd_baseline.loc[0,\"PKG_CACHE_LOOKUPS\"]} > 0 \\\n",
    "            then decimal((1-(float(pkg_cache_inserts-{mgd_baseline.loc[0,\"PKG_CACHE_INSERTS\"]})/float(pkg_cache_lookups-{mgd_baseline.loc[0,\"PKG_CACHE_LOOKUPS\"]})))*100,5,2)  \\\n",
    "            else -1 end as pkg_cache_hitratio \\\n",
    "        , pkg_cache_num_overflows-{mgd_baseline.loc[0,\"PKG_CACHE_NUM_OVERFLOWS\"]} as pkg_cache_num_overflows \\\n",
    "        from table(mon_get_database(-2)) as mgd\n",
    "else:\n",
    "    pkg_cache=%sql select decimal((1-(float(pkg_cache_inserts)/float(pkg_cache_lookups)))*100,5,2) as pkg_cache_hitratio \\\n",
    "        , pkg_cache_num_overflows \\\n",
    "    from table(mon_get_database(-2)) as mgd\n",
    "pkg_cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catalog Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if baselines == 1:\n",
    "    cat_cache=%sql select \\\n",
    "        case when cat_cache_lookups-{mgd_baseline.loc[0,\"CAT_CACHE_LOOKUPS\"]} > 0 \\\n",
    "            then decimal((1-(float(cat_cache_inserts-{mgd_baseline.loc[0,\"CAT_CACHE_INSERTS\"]})/float(cat_cache_lookups-{mgd_baseline.loc[0,\"PKG_CACHE_LOOKUPS\"]})))*100,5,2)  \\\n",
    "            else -1 end as cat_cache_hitratio \\\n",
    "        , cat_cache_overflows-{mgd_baseline.loc[0,\"CAT_CACHE_OVERFLOWS\"]} as cat_cache_overflows \\\n",
    "        from table(mon_get_database(-2)) as mgd\n",
    "else:\n",
    "    cat_cache=%sql select decimal((1-(float(cat_cache_inserts)/float(cat_cache_lookups)))*100,5,2) as cat_cache_hitratio \\\n",
    "        , cat_cache_overflows \\\n",
    "    from table(mon_get_database(-2)) as mgd\n",
    "cat_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if baselines == 1:\n",
    "    tl_data= %sql select log_reads-{mgtl_baseline.loc[0,\"LOG_READS\"]} as log_reads \\\n",
    "    , log_writes-{mgtl_baseline.loc[0,\"LOG_WRITES\"]} as log_writes \\\n",
    "from table(mon_get_transaction_log(-2)) as mgtl \n",
    "else:\n",
    "    tl_data= %sql select log_reads \\\n",
    "        , log_writes \\\n",
    "    from table(mon_get_transaction_log(-2)) as mgtl\n",
    "tl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql select decimal(100*(float(total_log_used)/float(total_log_available)),5,2) as tot_log_use_pct \\\n",
    "        , sec_logs_allocated \\\n",
    "        , sec_log_used_top \\\n",
    "    from table(mon_get_transaction_log(-2)) as mgtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sql with t1 as (select substr(start_time, 1, 10) as ts \\\n",
    "  ,count(*) as archives \\\n",
    "from sysibmadm.db_history \\\n",
    "where operation = 'X' \\\n",
    "   and start_time > current timestamp - 7 days \\\n",
    "group by substr(start_time, 1, 10) ) \\\n",
    "select avg(archives) as avg_arch_per_hour \\\n",
    "    , max(archives) as max_arch_in_hour \\\n",
    "    , min(archives) as min_arch_in_hour \\\n",
    "from t1 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if baselines == 1:\n",
    "    locking= %sql select deadlocks-{mgd_baseline.loc[0,\"DEADLOCKS\"]} as deadlocks \\\n",
    "        , lock_timeouts-{mgd_baseline.loc[0,\"LOCK_TIMEOUTS\"]} as lock_timeouts \\\n",
    "        , lock_escals-{mgd_baseline.loc[0,\"LOCK_ESCALS\"]} as lock_escals\\\n",
    "    from table(mon_get_database(-2)) as mgd\n",
    "else:\n",
    "     locking= %sql select deadlocks \\\n",
    "        , lock_timeouts \\\n",
    "        , lock_escals \\\n",
    "    from table(mon_get_database(-2)) as mgd\n",
    "locking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if baselines == 1:\n",
    "    sorts= %sql select \\\n",
    "        case when total_sorts-{mgd_baseline.loc[0,\"TOTAL_SORTS\"]} > 0 \\\n",
    "            then decimal(float(sort_overflows-{mgd_baseline.loc[0,\"SORT_OVERFLOWS\"]})/float(total_sorts-{mgd_baseline.loc[0,\"TOTAL_SORTS\"]}),5,2) \\\n",
    "            else 0 end as sort_overflow_pct \\\n",
    "    from table(mon_get_database(-2)) as mgd\n",
    "else:\n",
    "    sorts= %sql select \\\n",
    "        case when total_sorts >0 \\\n",
    "            then decimal(float(sort_overflows)/float(total_sorts),5,2) \\\n",
    "            else 0 end as sort_overflow_pct \\\n",
    "    from table(mon_get_database(-2)) as mgd\n",
    "sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
